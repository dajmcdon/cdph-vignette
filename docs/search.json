[{"path":"index.html","id":"about","chapter":"1 About","heading":"1 About","text":"sample book written Markdown. can use anything Pandoc’s Markdown supports; example, math equation \\(^2 + b^2 = c^2\\).","code":""},{"path":"index.html","id":"usage","chapter":"1 About","heading":"1.1 Usage","text":"bookdown chapter .Rmd file, .Rmd file can contain one (one) chapter. chapter must start first-level heading: # good chapter, can contain one (one) first-level heading.Use second-level higher headings within chapters like: ## short section ### even shorter section.index.Rmd file required, also first book chapter. homepage render book.","code":""},{"path":"index.html","id":"render-book","chapter":"1 About","heading":"1.2 Render book","text":"can render HTML version example book without changing anything:Find Build pane RStudio IDE, andFind Build pane RStudio IDE, andClick Build Book, select output format, select “formats” ’d like use multiple formats book source files.Click Build Book, select output format, select “formats” ’d like use multiple formats book source files.build book R console:render example PDF bookdown::pdf_book, ’ll need install XeLaTeX. recommended install TinyTeX (includes XeLaTeX): https://yihui.org/tinytex/.","code":"\nbookdown::render_book()"},{"path":"index.html","id":"preview-book","chapter":"1 About","heading":"1.3 Preview book","text":"work, may start local server live preview HTML book. preview update edit book save individual .Rmd files. can start server work session using RStudio add-“Preview book”, R console:","code":"\nbookdown::serve_book()"},{"path":"demonstrations-of-sliding-ar-and-arx-forecasters.html","id":"demonstrations-of-sliding-ar-and-arx-forecasters","chapter":"2 Demonstrations of sliding AR and ARX forecasters","heading":"2 Demonstrations of sliding AR and ARX forecasters","text":"key function epiprocess package epi_slide(), allows \nuser apply function formula-based computation variables \nepi_df running window n time steps (see following epiprocess\nvignette go basics function: “Slide computation \nsignal values”).\nequivalent sliding method epi_archive object can called using\nwrapper function epix_slide() (refer following vignette \nbasics function: “Work archive objects data\nrevisions”). \nkey difference epi_slide() performs version-aware\ncomputations. , function uses data \navailable time t reference time.vignette, use epi_slide() epix_slide() backtesting \narx_forecaster historical COVID-19 case data US Canada.\nprecisely, first demonstrate using epi_slide() slide ARX\nforecasters epi_df object compare results obtained using\ndifferent forecasting engines. compare results version-aware\nunaware forecasting, former obtained applying\nepix_slide() epi_archive object, latter obtained \napplying epi_slide() latest snapshot data.","code":"\nlibrary(epipredict)\nlibrary(epiprocess)\nlibrary(data.table)\nlibrary(parsnip)\nlibrary(magrittr)"},{"path":"demonstrations-of-sliding-ar-and-arx-forecasters.html","id":"comparing-different-forecasting-engines","chapter":"2 Demonstrations of sliding AR and ARX forecasters","heading":"2.1 Comparing different forecasting engines","text":"","code":""},{"path":"demonstrations-of-sliding-ar-and-arx-forecasters.html","id":"example-using-cli-and-case-data-from-us-states","chapter":"2 Demonstrations of sliding AR and ARX forecasters","heading":"2.1.1 Example using CLI and case data from US states","text":"First, download version history (ie. archive) percentage \ndoctor’s visits CLI (COVID-like illness) computed medical insurance\nclaims number new confirmed COVID-19 cases per 100,000 population\n(daily) 50 states COVIDcast API. process , \nmodification use sync = locf epix_merge() last\nversion observation can carried forward extrapolate unavailable\nversions less --date input archive.obtaining latest snapshot data, produce forecasts \ndata using default engine simple linear regression compare \nrandom forest.Note warnings forecast date less \nrecent update date data suppressed avoid cluttering \noutput., arx_forecaster() heavy lifting. creates leads \ntarget (respecting time stamps locations) along lags features\n(, response doctors visits), estimates forecasting model using \nspecified engine, creates predictions, non-parametric confidence bands.see predictions compare, plot top latest case\nrates. Note even though ’ve fitted model states,\n’ll just display \nresults two states, California (CA) Florida (FL), get sense \nmodel performance keeping graphic simple.two states interest, simple linear regression clearly performs better\nrandom forest terms accuracy predictions \nresult overconfident predictions (overly narrow confidence bands).\nThough, general, neither approach produces amazingly accurate forecasts.\n\nbehaviour rather different across states effects notable\nfactors age public health measures may important account \nforecasting. Including factors well making enhancements \ncorrecting outliers improvements one make simple\nmodel.1","code":"\ntheme_set(theme_bw())\n\ny <- readRDS(system.file(\"extdata\", \"all_states_covidcast_signals.rds\", \n                         package = \"epipredict\", mustWork = TRUE)) \n \ny1 <- y[[1]] %>% \n  select(geo_value, time_value, version = issue, percent_cli = value) %>%\n  as_epi_archive()\n\nx <- epix_merge(\n  y1, \n  y[[2]] %>% \n    select(geo_value, time_value, version = issue, case_rate = value) %>%\n    as_epi_archive(), \n  sync = \"locf\")\n# Latest snapshot of data, and forecast dates\nx_latest <- epix_as_of(x, max_version = max(x$versions_end)) \nfc_time_values <- seq(as.Date(\"2020-08-01\"), as.Date(\"2021-12-01\"), \n                      by = \"1 month\")\n\nk_week_ahead <- function(epi_df, outcome, predictors, ahead = 7, engine) {\n  epi_df %>%\n    epi_slide( \n      ~ arx_forecaster(\n        .x, outcome, predictors, engine, \n        args_list = arx_args_list(ahead = ahead)) %>%\n        extract2(\"predictions\") %>% \n        select(-c(geo_value, time_value)), \n      n = 120, \n      ref_time_values = fc_time_values, \n      new_col_name = \"fc\"\n    ) %>% \n    select(geo_value, time_value, starts_with(\"fc\")) %>%\n    mutate(engine_type = engine$engine)\n}\n\n# Generate the forecasts and bind them together\nfc <- bind_rows(\n  purrr::map_dfr(\n    c(7,14,21,28), \n    ~ k_week_ahead(\n      x_latest, \"case_rate\", c(\"case_rate\", \"percent_cli\"), .x,\n      engine = linear_reg())\n  ),\n  purrr::map_dfr(\n    c(7,14,21,28), \n    ~ k_week_ahead(\n      x_latest, \"case_rate\", c(\"case_rate\", \"percent_cli\"), .x,\n      engine = rand_forest(mode = \"regression\"))\n  )) %>% \n  mutate(.pred_distn = nested_quantiles(fc_.pred_distn)) %>%\n  unnest(.pred_distn) %>% \n  pivot_wider(names_from = tau, values_from = q) \nfc_cafl <- fc %>% filter(geo_value %in% c(\"ca\", \"fl\"))\nx_latest_cafl <- x_latest %>% filter(geo_value %in% c(\"ca\", \"fl\"))\n\nggplot(fc_cafl, aes(fc_target_date, group = time_value, fill = engine_type)) + \n  geom_line(data = x_latest_cafl, aes(x = time_value, y = case_rate),\n            inherit.aes = FALSE, color = \"gray50\") +\n  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`), alpha = 0.4) +\n  geom_line(aes(y = fc_.pred)) + \n  geom_point(aes(y = fc_.pred), size = 0.5) +\n  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +\n  facet_grid(vars(geo_value), vars(engine_type), scales = \"free\") +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(x = \"Date\", y = \"Reported COVID-19 case rates\") +\n  theme(legend.position = \"none\")"},{"path":"demonstrations-of-sliding-ar-and-arx-forecasters.html","id":"example-using-case-data-from-canada","chapter":"2 Demonstrations of sliding AR and ARX forecasters","heading":"2.1.2 Example using case data from Canada","text":"leveraging flexibility epiprocess, can apply techniques\ndata sources. Since collaborators British Columbia,\nCanada, ’ll essentially thing Canada .COVID-19 Canada Open Data Working Group collects\ndaily time series data COVID-19 cases, deaths, recoveries, testing \nvaccinations health region province levels. Data collected \npublicly available sources government datasets news releases.\nUnfortunately, simple versioned source, created \nGithub commit history.First, load versioned case rates provincial level. converting\n7-day averages (due highly variable provincial reporting\nmismatches), convert data epi_archive object, extract\nlatest version . Finally, run forcasting exercise \nAmerican data, compare forecasts produced using simple\nlinear regression using boosted regression trees.figures shows results provinces.approaches tend produce quite volatile forecasts (point predictions)\n/overly confident (narrow bands), particularly boosted\nregression trees used. meant simple demonstration \nsliding different engines arx_forecaster, may devote another\nvignette work improving predictive modelling using suite tools\navailable epipredict.","code":"\n# source(\"drafts/canada-case-rates.R)\ncan <- readRDS(\n  system.file(\"extdata\", \"can_prov_cases.rds\", \n              package = \"epipredict\", mustWork = TRUE)\n  ) %>%\n  group_by(version, geo_value) %>% \n  arrange(time_value) %>% \n  mutate(cr_7dav = RcppRoll::roll_meanr(case_rate, n = 7L)) #%>%\n  #filter(geo_value %in% c('Alberta', \"BC\"))\ncan <- as_epi_archive(can)\ncan_latest <- epix_as_of(can, max_version = max(can$DT$version))\n\n\n# Generate the forecasts, and bind them together\ncan_fc <- bind_rows(\n  purrr:::map_dfr(\n    c(7,14,21,28), \n    ~ k_week_ahead(can_latest, \"cr_7dav\", \"cr_7dav\", .x, linear_reg())\n  ),\n  purrr::map_dfr(\n    c(7,14,21,28),\n    ~ k_week_ahead(can_latest, \"cr_7dav\", \"cr_7dav\", .x, \n                   boost_tree(mode = \"regression\", trees = 20))\n  )) %>% \n  mutate(.pred_distn = nested_quantiles(fc_.pred_distn)) %>% \n  unnest(.pred_distn) %>% \n  pivot_wider(names_from = tau, values_from = q) \nggplot(can_fc %>% filter(engine_type == \"lm\"), \n       aes(x = fc_target_date, group = time_value)) +\n  coord_cartesian(xlim = lubridate::ymd(c(\"2020-12-01\", NA))) +\n  geom_line(data = can_latest, aes(x = time_value, y = cr_7dav),\n            inherit.aes = FALSE, color = \"gray50\") +\n  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value),\n              alpha = 0.4) +\n  geom_line(aes(y = fc_.pred)) + geom_point(aes(y = fc_.pred), size = 0.5) +\n  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +\n  facet_wrap(~geo_value, scales = \"free_y\", ncol = 3) +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +\n  labs(title = \"Using simple linear regression\", x = \"Date\", \n       y = \"Reported COVID-19 case rates\") +\n  theme(legend.position = \"none\")  \nggplot(can_fc %>% filter(engine_type == \"xgboost\"), \n       aes(x = fc_target_date, group = time_value)) +\n  coord_cartesian(xlim = lubridate::ymd(c(\"2020-12-01\", NA))) +\n  geom_line(data = can_latest, aes(x = time_value, y = cr_7dav),\n            inherit.aes = FALSE, color = \"gray50\") +\n  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value),\n              alpha = 0.4) +\n  geom_line(aes(y = fc_.pred)) + geom_point(aes(y = fc_.pred), size = 0.5) +\n  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +\n  facet_wrap(~ geo_value, scales = \"free_y\", ncol = 3) +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +\n  labs(title = \"Using boosted regression trees\", x = \"Date\", \n       y = \"Reported COVID-19 case rates\") +\n  theme(legend.position = \"none\")  "},{"path":"demonstrations-of-sliding-ar-and-arx-forecasters.html","id":"version-aware-and-unaware-forecasting","chapter":"2 Demonstrations of sliding AR and ARX forecasters","heading":"2.2 Version-aware and unaware forecasting","text":"","code":""},{"path":"demonstrations-of-sliding-ar-and-arx-forecasters.html","id":"example-using-case-data-from-us-states","chapter":"2 Demonstrations of sliding AR and ARX forecasters","heading":"2.2.1 Example using case data from US states","text":"now employ forecaster uses properly-versioned data (\navailable real-time) forecast future COVID-19 case rates \ncurrent past COVID-19 case rates states. , can make\nforecasts archive, x, compare forecasts latest\ndata, x_latest using general set-. version-aware\nforecasting, note x fed epix_slide(), version-unaware\nforecasting, x_latest fed epi_slide(). #%% update include\npercent_cli issue fixed?Now can plot results top latest case rates. , display focus results FL CA simplicity., observe results great two states, \n’s likely due simplicity model (ex. omission key\nfactors age public health measures) quality data (ex.\npersonally corrected anomalies data).shall leave reader try version aware unaware\nforecasting exercise Canadian case rate data. code \nAmerican state data readily adaptable purpose.","code":"\nk_week_ahead_as_of <- function(ahead = 7, version_aware = TRUE) {\n  if (version_aware) {\n    epix_slide(\n      x,\n      ~ arx_forecaster(.x, \"case_rate\", \"case_rate\",\n                       args_list = arx_args_list(ahead = ahead)) %>%\n        extract2(\"predictions\") %>%\n        select(-c(geo_value, time_value)),\n      n = 120, \n      ref_time_values = fc_time_values, \n      new_col_name = \"fc\") %>% \n      mutate(engine_type = \"lm\", version_aware = version_aware)\n  } else {\n    k_week_ahead(x_latest, \"case_rate\", \"case_rate\", ahead, linear_reg()) %>%\n      mutate(version_aware = version_aware)\n  }\n}\n\n# Generate the forecasts, and bind them together\nfc <- bind_rows(\n  purrr::map_dfr(c(7,14,21,28), ~ k_week_ahead_as_of(.x, TRUE)),\n  purrr::map_dfr(c(7,14,21,28), ~ k_week_ahead_as_of(.x, FALSE))\n  ) %>% \n  mutate(.pred_distn = nested_quantiles(fc_.pred_distn)) %>% \n  unnest(.pred_distn) %>% \n  pivot_wider(names_from = tau, values_from = q) \nfc_cafl = fc %>% filter(geo_value %in% c(\"ca\", \"fl\"))\nx_latest_cafl = x_latest %>% filter(geo_value %in% c(\"ca\", \"fl\"))\n\nggplot(fc_cafl, aes(x = fc_target_date, group = time_value, fill = version_aware)) +\n  geom_line(data = x_latest_cafl, aes(x = time_value, y = case_rate),\n            inherit.aes = FALSE, color = \"gray50\") +\n  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`), alpha = 0.4) +\n  geom_line(aes(y = fc_.pred)) + geom_point(aes(y = fc_.pred), size = 0.5) +\n  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +\n  facet_grid(geo_value ~ version_aware, scales = \"free\", \n             labeller = labeller(version_aware = label_both)) +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +\n  labs(x = \"Date\", y = \"Reported COVID-19 case rates\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  theme(legend.position = \"none\")"},{"path":"examples-of-preprocessing-and-models.html","id":"examples-of-preprocessing-and-models","chapter":"3 Examples of Preprocessing and Models","heading":"3 Examples of Preprocessing and Models","text":"","code":""},{"path":"examples-of-preprocessing-and-models.html","id":"introduction","chapter":"3 Examples of Preprocessing and Models","heading":"3.1 Introduction","text":"epipredict package utilizes tidymodels framework, namely\n{recipes} \ndplyr-like pipeable sequences\nfeature engineering {parsnip} \nunified interface range models.epipredict additional customized feature engineering preprocessing\nsteps, step_epi_lag(), step_population_scaling(),\nstep_epi_naomit(). can used along \nsteps recipes package feature engineering.vignette, illustrate examples use epipredict\nrecipes parsnip different purposes epidemiological forecasting.\nfocus basic autoregressive models, COVID cases \ndeaths near future predicted using linear combination cases \ndeaths near past.remaining vignette split three sections. first section, \nuse Poisson regression predict death counts. second section,\nuse linear regression predict death rates. Last least, \ncreate classification model hotspot predictions.","code":"\nlibrary(epidatr)\nlibrary(epiprocess)\nlibrary(epipredict)\nlibrary(recipes)\nlibrary(parsnip)\nlibrary(workflows)\nlibrary(poissonreg)"},{"path":"examples-of-preprocessing-and-models.html","id":"poisson-regression","chapter":"3 Examples of Preprocessing and Models","heading":"3.2 Poisson Regression","text":"COVID-19, US Center Disease Control Prevention (CDC) collected\nmodels\nforecasts characterize state outbreak course. use\ninform public health decision makers potential consequences \ndeploying control measures.One outcomes CDC forecasts death counts COVID-19.\nAlthough many state---art models, choose use Poisson\nregression, textbook example modeling count data, illustration\nusing epipredict package existing tidymodels packages.counts_subset dataset comes epidatr package, \ncontains number confirmed cases deaths June 4, 2021 \nDec 31, 2021 U.S. states.wish predict 7-day ahead death counts lagged cases deaths.\nFurthermore, let state dummy variable. Using differential\nintercept coefficients, can allow intercept shift states.\\(\\mu_{t+7} = \\mathbb{E}(y_{t+7})\\), \\(y_{t+7}\\) assumed follow \nPoisson distribution mean \\(\\mu_{t+7}\\); \\(s_{\\text{state}}\\) dummy\nvariables state take values either 0 1.Preprocessing steps performed prepare \ndata model fitting. diving , helpful understand roles recipes framework.","code":"\ngeos <- c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")\nx <- covidcast(\n  data_source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = \"*\") %>%\n  fetch_tbl() %>%\n  filter(geo_value %in% geos) %>%\n  select(geo_value, time_value, cases = value)\n\ny <- covidcast(\n  data_source = \"jhu-csse\",\n  signals = \"deaths_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = \"*\") %>%\n  fetch_tbl() %>%\n  filter(geo_value %in% geos) %>%\n  select(geo_value, time_value, deaths = value)\n\ncounts_subset <- full_join(x, y, by = c(\"geo_value\", \"time_value\")) %>%\n  as_epi_df()"},{"path":"examples-of-preprocessing-and-models.html","id":"aside-on-recipes","chapter":"3 Examples of Preprocessing and Models","heading":"3.2.0.1 Aside on recipes","text":"recipes can assign one roles column data. roles\nrestricted predefined set; can anything.\nconventional situations, typically “predictor” /\n“outcome”. Additional roles enable targeted step_*() operations specific\nvariables groups variables.case, role predictor given explanatory variables \nright-hand side model (equation ).\nrole outcome response variable\nwish predict. geo_value time_value predefined roles\nunique epipredict package. Since work epi_df\nobjects, datasets geo_value time_value passed \nautomatically two roles assigned appropriate columns data.recipes package also allows manual alterations roles\nbulk. handy functions can used together help us\nmanipulate variable roles easily.update_role() alters existing role recipe assigns initial role\nvariables yet declared role.add_role() adds additional role variables already role \nrecipe, without overwriting old roles.remove_role() eliminates single existing role recipe.","code":""},{"path":"examples-of-preprocessing-and-models.html","id":"end-aside","chapter":"3 Examples of Preprocessing and Models","heading":"3.2.0.2 End aside","text":"Notice following preprocessing steps, used add_role() \ngeo_value_factor since, currently, default role raw, \nlike reuse variable predictors.specifying preprocessing steps, use parsnip package \nmodeling producing prediction death count, 7 days \nlatest available date dataset.Note time_value corresponds last available date \ntraining set, target date forecast\n(2022-01-07).Let’s take look fit:now, ’ve used Poisson regression model count data. Poisson\nregression can also used model rate data, case rates death\nrates, incorporating offset terms model.\\(\\log(\\text{population})\\) log state population \nused scale count data left-hand side equation. offset\nsimply predictor coefficient fixed 1 rather estimated.several ways model rate data given count population data.\nFirst, parsnip framework, specify formula fit().\nHowever, lose ability use recipes framework \ncreate new variables since variables exist \noriginal dataset (, , lags leads) called directly fit().Alternatively, step_population_scaling() layer_population_scaling()\nepipredict package can perform population scaling provide \npopulation data, illustrate next section.","code":"\ncounts_subset <- counts_subset %>%\n  mutate(geo_value_factor = as.factor(geo_value)) %>%\n  as_epi_df()\n\nepi_recipe(counts_subset)\n\nr <- epi_recipe(counts_subset) %>%\n  add_role(geo_value_factor, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  ## Occasionally, data reporting errors / corrections result in negative\n  ## cases / deaths\n  step_mutate(cases = pmax(cases, 0), deaths = pmax(deaths, 0)) %>%  \n  step_epi_lag(cases, deaths, lag = c(0, 7)) %>%\n  step_epi_ahead(deaths, ahead = 7, role = \"outcome\") %>%\n  step_epi_naomit()\nlatest <- get_test_data(r, counts_subset)\n\nwf <- epi_workflow(r, parsnip::poisson_reg()) %>%\n  fit(counts_subset)\n\npredict(wf, latest) %>% filter(!is.na(.pred))\n#> An `epi_df` object, 5 x 3 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2023-04-04 16:26:23\n#> \n#> # A tibble: 5 × 3\n#>   geo_value time_value .pred\n#> * <chr>     <date>     <dbl>\n#> 1 ca        2021-12-31 108. \n#> 2 fl        2021-12-31 270. \n#> 3 nj        2021-12-31  22.5\n#> 4 ny        2021-12-31  94.8\n#> 5 tx        2021-12-31  91.0\nextract_fit_engine(wf)\n#> \n#> Call:  stats::glm(formula = ..y ~ ., family = stats::poisson, data = data)\n#> \n#> Coefficients:\n#>         (Intercept)  geo_value_factor_fl  \n#>           3.970e+00           -1.487e-01  \n#> geo_value_factor_nj  geo_value_factor_ny  \n#>          -1.425e+00           -6.865e-01  \n#> geo_value_factor_tx          lag_0_cases  \n#>           3.025e-01            1.339e-05  \n#>         lag_7_cases         lag_0_deaths  \n#>           1.717e-06            1.731e-03  \n#>        lag_7_deaths  \n#>           8.566e-04  \n#> \n#> Degrees of Freedom: 984 Total (i.e. Null);  976 Residual\n#> Null Deviance:       139600 \n#> Residual Deviance: 58110     AIC: 62710"},{"path":"examples-of-preprocessing-and-models.html","id":"linear-regression","chapter":"3 Examples of Preprocessing and Models","heading":"3.3 Linear Regression","text":"COVID-19, CDC required submission case death count predictions.\nHowever, Delphi Group preferred train rate data instead, \nputs different locations similar scale (eliminating need location-specific intercepts).\ncan use liner regression predict death\nrates use state population data scale rates counts.2 \nusing layer_population_scaling() epipredict package.Additionally, forecasts submitted, prediction intervals \nprovided along point estimates. can obtained via postprocessing\nusing\nlayer_residual_quantiles(). worth pointing , however, \nlayer_residual_quantiles() used population scaling else\ntransformation make results uninterpretable.wish, now, predict 7-day ahead death counts lagged case rates death\nrates, along extra behaviourial predictors. Namely, use survey data\nCOVID-19 Trends Impact Survey.survey data provides estimated percentage people wore mask \ntime public past 7 days estimated\npercentage respondents reported people encountered\npublic past 7 days maintained distance least 6 feet.State-wise population data 2019 U.S. Census included package\nused layer_population_scaling().Rather using raw mask-wearing / social-distancing metrics, sake\nillustration, ’ll convert categorical predictors.take subset death rate case rate data built-dataset\ncase_death_rate_subset.Preprocessing steps rely functions epipredict package well\nrecipes package.\nalso many functions recipes package allow \nscalar transformations,\nlog transformations data centering. case, \ncenter numerical predictors allow meaningful interpretation \nintercept.sanity check can examine structure training data:directly predicting results, need add postprocessing layers \nobtain death counts instead death rates. Note rates used \nfar “per 100K people” rather “per person”. ’ll also use quantile\nregression quantile_reg engine rather ordinary least squares\ncreate median predictions 90% prediction interval.columns marked *_scaled rescaled correct units, \ncase deaths rather deaths per 100K people (remain .pred).look prediction intervals:Last least, let’s take look regression fit check \ncoefficients:","code":"\nbehav_ind_mask <- covidcast(\n  data_source = \"fb-survey\",\n  signals = \"smoothed_wwearing_mask_7d\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = \"*\")  %>%\n  fetch_tbl() %>%\n  filter(geo_value %in% geos) %>%\n  select(geo_value, time_value, masking = value)\n\nbehav_ind_distancing <- covidcast(\n  data_source = \"fb-survey\",\n  signals = \"smoothed_wothers_distanced_public\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = \"*\")  %>%\n  fetch_tbl() %>%\n  filter(geo_value %in% geos) %>%\n  select(geo_value, time_value, distancing = value) \n\npop_dat <- state_census %>% select(abbr, pop)\n\nbehav_ind <- behav_ind_mask %>%\n  full_join(behav_ind_distancing, by = c(\"geo_value\", \"time_value\")) \njhu <- filter(\n  case_death_rate_subset,\n  time_value >= \"2021-06-04\", \n  time_value <= \"2021-12-31\",\n  geo_value %in% c(\"ca\",\"fl\",\"tx\",\"ny\",\"nj\")\n)\njhu <- jhu %>%\n  mutate(geo_value_factor = as.factor(geo_value)) %>%\n  left_join(behav_ind, by = c(\"geo_value\", \"time_value\")) %>%\n  as_epi_df()\n            \nr <- epi_recipe(jhu) %>%\n  add_role(geo_value_factor, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%\n  step_mutate(masking = cut_number(masking, 5), \n              distancing = cut_number(distancing, 5)) %>%\n  step_epi_ahead(death_rate, ahead = 7, role = \"outcome\") %>%\n  step_center(contains(\"lag\"), role = \"predictor\") %>%\n  step_epi_naomit()\nglimpse(slice_sample(bake(prep(r, jhu), jhu), n = 6))\n#> Rows: 6\n#> Columns: 17\n#> $ time_value          <date> 2021-07-22, 2021-07-25, 2021-…\n#> $ geo_value           <chr> \"tx\", \"ny\", \"ca\", \"ca\", \"fl\", …\n#> $ case_rate           <dbl> 14.282426, 6.909115, 9.655756,…\n#> $ death_rate          <dbl> 0.0836880, 0.0273350, 0.201758…\n#> $ masking             <fct> \"[42.7,52.8]\", \"[42.7,52.8]\", …\n#> $ distancing          <fct> \"(18.4,19.8]\", \"(18.4,19.8]\", …\n#> $ geo_value_factor_fl <dbl> 0, 0, 0, 0, 1, 0\n#> $ geo_value_factor_nj <dbl> 0, 0, 0, 0, 0, 0\n#> $ geo_value_factor_ny <dbl> 0, 1, 0, 0, 0, 1\n#> $ geo_value_factor_tx <dbl> 1, 0, 0, 0, 0, 0\n#> $ lag_0_case_rate     <dbl> -12.65924, -20.03255, -17.2859…\n#> $ lag_7_case_rate     <dbl> -18.420571, -22.365630, -12.43…\n#> $ lag_14_case_rate    <dbl> -21.587091, -24.008687, -13.60…\n#> $ lag_0_death_rate    <dbl> -0.1981856, -0.2545386, -0.080…\n#> $ lag_7_death_rate    <dbl> -0.1865082, -0.2523222, -0.068…\n#> $ lag_14_death_rate   <dbl> -0.2054840, -0.2567549, -0.065…\n#> $ ahead_7_death_rate  <dbl> 0.1221261, 0.0347229, 0.206839…\nf <- frosting() %>%\n  layer_predict() %>%\n  layer_add_target_date(\"2022-01-07\") %>% \n  layer_threshold(.pred, lower = 0) %>%\n  layer_quantile_distn() %>%\n  layer_naomit(.pred) %>%\n  layer_population_scaling(\n    .pred, .pred_distn, \n    df = pop_dat, \n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\"), \n    df_pop_col = \"pop\")\n\nwf <- epi_workflow(r, quantile_reg(tau = c(.05, .5, .95))) %>%\n  fit(jhu) %>%\n  add_frosting(f)\n\nlatest <- get_test_data(recipe = r, x = jhu)\np <- predict(wf, latest)\np\n#> An `epi_df` object, 5 x 7 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25\n#> \n#> # A tibble: 5 × 7\n#>   geo_value time_value               .pred target_date\n#> * <chr>     <date>                  <dist> <date>     \n#> 1 ca        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07 \n#> 2 fl        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07 \n#> 3 nj        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07 \n#> 4 ny        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07 \n#> 5 tx        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07 \n#> # ℹ 3 more variables: .pred_distn <dist>,\n#> #   .pred_scaled <dist>, .pred_distn_scaled <dist>\np %>%\n  select(geo_value, target_date, .pred_scaled, .pred_distn_scaled) %>%\n  mutate(.pred_distn_scaled = nested_quantiles(.pred_distn_scaled)) %>%\n  unnest(.pred_distn_scaled) %>%\n  pivot_wider(names_from = tau, values_from = q)\n#> # A tibble: 5 × 5\n#>   geo_value target_date        .pred_scaled `0.25` `0.75`\n#>   <chr>     <date>                   <dist>  <dbl>  <dbl>\n#> 1 ca        2022-01-07  [0.05, 0.95]<q-rng>   48.8   94.0\n#> 2 fl        2022-01-07  [0.05, 0.95]<q-rng>   48.4  104. \n#> 3 nj        2022-01-07  [0.05, 0.95]<q-rng>   45.5   68.7\n#> 4 ny        2022-01-07  [0.05, 0.95]<q-rng>  108.   163. \n#> 5 tx        2022-01-07  [0.05, 0.95]<q-rng>   68.6  107.#> Call:\n#> quantreg::rq(formula = ..y ~ ., tau = ~c(0.05, 0.5, 0.95), data = data, \n#>     na.action = function (object, ...) \n#>     UseMethod(\"na.omit\"), method = \"br\", model = FALSE)\n#> \n#> Coefficients:\n#>                        tau= 0.05     tau= 0.50    tau= 0.95\n#> (Intercept)          0.210811625  0.2962574475  0.417583265\n#> geo_value_factor_fl  0.032085820  0.0482361119  0.171126713\n#> geo_value_factor_nj  0.007313762 -0.0033797953 -0.025251865\n#> geo_value_factor_ny -0.001489163 -0.0199485947 -0.032635584\n#> geo_value_factor_tx  0.029077485  0.0391980273  0.071961515\n#> lag_0_case_rate     -0.001636588 -0.0011625693 -0.001430622\n#> lag_7_case_rate      0.004700752  0.0057822095  0.006912655\n#> lag_14_case_rate     0.001715816  0.0004224753  0.003448733\n#> lag_0_death_rate     0.462341754  0.5274192012  0.164856372\n#> lag_7_death_rate    -0.007368501  0.1132903956  0.172687438\n#> lag_14_death_rate   -0.072500707 -0.0270474349  0.181279299\n#> \n#> Degrees of freedom: 950 total; 939 residual"},{"path":"examples-of-preprocessing-and-models.html","id":"classification","chapter":"3 Examples of Preprocessing and Models","heading":"3.4 Classification","text":"Sometimes preferable create predictive model surges upswings\nrather raw values. case,\ntarget predict future increased case rates (denoted ),\ndecreased case rates (), flat case rates (flat) relative current\nlevel. models may \nreferred “hotspot prediction models”. follow analysis\nMcDonald, Bien, Green, Hu, et al. extend application\npredict three categories instead two.Hotspot prediction uses categorical outcome variable defined terms \nrelative change \\(Y_{\\ell, t+}\\) compared \\(Y_{\\ell, t}\\).\n\\(Y_{\\ell, t}\\) denotes case rates location \\(\\ell\\) time \\(t\\).\ndefine response variables follows:\\[\nZ_{\\ell, t}=\n    \\begin{cases}\n      \\text{}, & \\text{}\\ Y^{\\Delta}_{\\ell, t} > 0.25 \\\\\n      \\text{}, & \\text{}\\  Y^{\\Delta}_{\\ell, t} < -0.20\\\\\n      \\text{flat}, & \\text{otherwise}\n    \\end{cases}\n\\]\\(Y^{\\Delta}_{\\ell, t} = (Y_{\\ell, t}- Y_{\\ell, t-7})\\ /\\ (Y_{\\ell, t-7})\\).\nsay location \\(\\ell\\) hotspot time \\(t\\) \\(Z_{\\ell,t}\\) \n, meaning number newly reported cases past 7 days \nincreased least 25% compared preceding week. \\(Z_{\\ell,t}\\)\ncategorized , suggests least 20%\ndecrease newly reported cases past 7 days (20% decrease inverse 25% increase). Otherwise, \nconsider trend flat.expression multinomial regression use follows:\n\\[\n\\pi_{j}(x) = \\text{Pr}(Z_{\\ell,t} = j|x) = \\frac{e^{g_j(x)}}{1 + \\sum_{k=0}^2 g_j(x) }\n\\]\n\\(j\\) either , flat, upPreprocessing steps similar previous models additional step\ncategorizing response variables. , use subset death rate case rate data built-dataset\ncase_death_rate_subset.fit multinomial regression examine predictions:can also look estimated coefficients model summary information:One also use formula epi_recipe() achieve results \n. However, one add_formula(), add_recipe(), \nworkflow_variables() can specified. purpose demonstrating\nadd_formula rather add_recipe, prep bake recipe \nreturn data.frame used model fitting.","code":"\njhu <- case_death_rate_subset %>%\n  dplyr::filter(time_value >= \"2021-06-04\", \n                time_value <= \"2021-12-31\",\n  geo_value %in% c(\"ca\",\"fl\",\"tx\",\"ny\",\"nj\")) %>%\n  mutate(geo_value_factor = as.factor(geo_value)) %>%\n  as_epi_df()\n\nr <- epi_recipe(jhu) %>%\n  add_role(time_value, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%\n  step_epi_ahead(case_rate, ahead = 7, role = \"predictor\") %>%\n  step_mutate(\n    pct_diff_ahead = case_when(\n      lag_7_case_rate == 0 ~ 0,\n      TRUE ~ (ahead_7_case_rate - lag_0_case_rate) / lag_0_case_rate),\n    pct_diff_wk1 = case_when(\n      lag_7_case_rate == 0 ~ 0, \n      TRUE ~ (lag_0_case_rate - lag_7_case_rate) / lag_7_case_rate),\n    pct_diff_wk2 = case_when(\n      lag_14_case_rate == 0 ~ 0,\n      TRUE ~ (lag_7_case_rate - lag_14_case_rate) / lag_14_case_rate)) %>%\n  step_mutate(\n    response = case_when(\n      pct_diff_ahead < -0.20 ~ \"down\",\n      pct_diff_ahead > 0.25 ~ \"up\",\n      TRUE ~ \"flat\"), \n    role = \"outcome\") %>% \n  step_rm(death_rate, case_rate, lag_0_case_rate,  lag_7_case_rate, \n          lag_14_case_rate, ahead_7_case_rate, pct_diff_ahead) %>%\n  step_epi_naomit()\nwf <- epi_workflow(r, parsnip::multinom_reg()) %>%\n  fit(jhu)\n\nlatest <- get_test_data(recipe = r, x = jhu)\npredict(wf, latest) %>% filter(!is.na(.pred_class))\n#> An `epi_df` object, 5 x 3 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25\n#> \n#> # A tibble: 5 × 3\n#>   geo_value time_value .pred_class\n#> * <chr>     <date>     <fct>      \n#> 1 ca        2021-12-31 up         \n#> 2 fl        2021-12-31 up         \n#> 3 nj        2021-12-31 up         \n#> 4 ny        2021-12-31 up         \n#> 5 tx        2021-12-31 flat\nextract_fit_engine(wf)\n#> Call:\n#> nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n#> \n#> Coefficients:\n#>      (Intercept)   time_value geo_value_factor_fl\n#> flat   -58.11177  0.003162471          -0.5978151\n#> up      46.45080 -0.002429847          -0.4682080\n#>      geo_value_factor_nj geo_value_factor_ny\n#> flat            1.350320            3.113677\n#> up              1.572085            3.172692\n#>      geo_value_factor_tx pct_diff_wk1 pct_diff_wk2\n#> flat          -0.3010305     1.263089     3.610543\n#> up            -0.2505232     2.194646     4.266267\n#> \n#> Residual Deviance: 1529.929 \n#> AIC: 1561.929\nb <- bake(prep(r, jhu), jhu)\n\nepi_workflow() %>%\n  add_formula(response ~ geo_value + time_value + pct_diff_wk1 + pct_diff_wk2) %>%\n  add_model(parsnip::multinom_reg()) %>%\n  fit(data = b)\n#> ══ Workflow [trained] ══════════════════════════════════════\n#> Preprocessor: Formula\n#> Model: multinom_reg()\n#> \n#> ── Preprocessor ────────────────────────────────────────────\n#> response ~ geo_value + time_value + pct_diff_wk1 + pct_diff_wk2\n#> \n#> ── Model ───────────────────────────────────────────────────\n#> Call:\n#> nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n#> \n#> Coefficients:\n#>      (Intercept) geo_valuefl geo_valuenj geo_valueny\n#> flat   -58.11158  -0.5978159    1.350325    3.113684\n#> up      46.45071  -0.4682087    1.572090    3.172698\n#>      geo_valuetx   time_value pct_diff_wk1 pct_diff_wk2\n#> flat  -0.3010308  0.003162461     1.263093     3.610536\n#> up    -0.2505236 -0.002429839     2.194649     4.266259\n#> \n#> Residual Deviance: 1529.929 \n#> AIC: 1561.929"},{"path":"examples-of-preprocessing-and-models.html","id":"benefits-of-lagging-and-leading-in-epipredict","chapter":"3 Examples of Preprocessing and Models","heading":"3.5 Benefits of Lagging and Leading in epipredict","text":"step_epi_ahead step_epi_lag functions epipredict package\nhandy creating correct lags leads future predictions.Let’s start simple dataset preprocessing:want predict death rates 2022-01-07, 7 days ahead \nlatest available date dataset.compare two methods trying create lags leads:Notice difference number rows b1 b2 returns. \nsecond version, one doesn’t use step_epi_ahead step_epi_lag,\nomitted dates compared one used epipredict functions.model trained based recipes functions predict 7 days ahead \n2021-12-24\ninstead 7 days ahead 2021-12-31.","code":"\nex <- filter(\n  case_death_rate_subset, \n  time_value >= \"2021-12-01\", \n  time_value <= \"2021-12-31\",\n  geo_value == \"ca\"\n)\n\ndim(ex)\n#> [1] 31  4\np1 <- epi_recipe(ex) %>%\n  step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%\n  step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%\n  step_epi_ahead(death_rate, ahead = 7, role = \"outcome\") %>%\n  step_epi_naomit() %>%\n  prep()\n\nb1 <- bake(p1, ex)\nb1\n#> # A tibble: 17 × 11\n#>    time_value geo_value case_rate death_rate lag_0_case_rate\n#>    <date>     <chr>         <dbl>      <dbl>           <dbl>\n#>  1 2021-12-15 ca             15.8      0.157            15.8\n#>  2 2021-12-16 ca             16.3      0.155            16.3\n#>  3 2021-12-17 ca             16.9      0.158            16.9\n#>  4 2021-12-18 ca             17.6      0.164            17.6\n#>  5 2021-12-19 ca             19.1      0.165            19.1\n#>  6 2021-12-20 ca             20.6      0.164            20.6\n#>  7 2021-12-21 ca             22.6      0.165            22.6\n#>  8 2021-12-22 ca             26.2      0.163            26.2\n#>  9 2021-12-23 ca             30.8      0.167            30.8\n#> 10 2021-12-24 ca             33.8      0.167            33.8\n#> 11 2021-12-25 ca             32.6      0.153            32.6\n#> 12 2021-12-26 ca             34.5      0.153            34.5\n#> 13 2021-12-27 ca             48.4      0.132            48.4\n#> 14 2021-12-28 ca             54.9      0.142            54.9\n#> 15 2021-12-29 ca             63.7      0.140            63.7\n#> 16 2021-12-30 ca             76.0      0.140            76.0\n#> 17 2021-12-31 ca             84.4      0.142            84.4\n#> # ℹ 6 more variables: lag_7_case_rate <dbl>,\n#> #   lag_14_case_rate <dbl>, lag_0_death_rate <dbl>,\n#> #   lag_7_death_rate <dbl>, lag_14_death_rate <dbl>,\n#> #   ahead_7_death_rate <dbl>\n\n\np2 <- epi_recipe(ex) %>%\n  step_mutate(lag0case_rate = lag(case_rate, 0),\n              lag7case_rate = lag(case_rate, 7),\n              lag14case_rate = lag(case_rate, 14),\n              lag0death_rate = lag(death_rate, 0),\n              lag7death_rate = lag(death_rate, 7),\n              lag14death_rate = lag(death_rate, 14),\n              ahead7death_rate = lead(death_rate, 7)) %>%\n  step_epi_naomit() %>%\n  prep()\n\nb2 <- bake(p2, ex)\nb2\n#> # A tibble: 10 × 11\n#>    time_value geo_value case_rate death_rate lag0case_rate\n#>    <date>     <chr>         <dbl>      <dbl>         <dbl>\n#>  1 2021-12-15 ca             15.8      0.157          15.8\n#>  2 2021-12-16 ca             16.3      0.155          16.3\n#>  3 2021-12-17 ca             16.9      0.158          16.9\n#>  4 2021-12-18 ca             17.6      0.164          17.6\n#>  5 2021-12-19 ca             19.1      0.165          19.1\n#>  6 2021-12-20 ca             20.6      0.164          20.6\n#>  7 2021-12-21 ca             22.6      0.165          22.6\n#>  8 2021-12-22 ca             26.2      0.163          26.2\n#>  9 2021-12-23 ca             30.8      0.167          30.8\n#> 10 2021-12-24 ca             33.8      0.167          33.8\n#> # ℹ 6 more variables: lag7case_rate <dbl>,\n#> #   lag14case_rate <dbl>, lag0death_rate <dbl>,\n#> #   lag7death_rate <dbl>, lag14death_rate <dbl>,\n#> #   ahead7death_rate <dbl>\ndates_used_in_training1 <- b1 %>% \n  select(- ahead_7_death_rate) %>% \n  na.omit() %>% \n  select(time_value)\ndates_used_in_training1\n#> # A tibble: 17 × 1\n#>    time_value\n#>    <date>    \n#>  1 2021-12-15\n#>  2 2021-12-16\n#>  3 2021-12-17\n#>  4 2021-12-18\n#>  5 2021-12-19\n#>  6 2021-12-20\n#>  7 2021-12-21\n#>  8 2021-12-22\n#>  9 2021-12-23\n#> 10 2021-12-24\n#> 11 2021-12-25\n#> 12 2021-12-26\n#> 13 2021-12-27\n#> 14 2021-12-28\n#> 15 2021-12-29\n#> 16 2021-12-30\n#> 17 2021-12-31\n\ndates_used_in_training2 <- b2 %>% \n  select(- ahead7death_rate) %>% \n  na.omit() %>% \n  select(time_value)\ndates_used_in_training2\n#> # A tibble: 10 × 1\n#>    time_value\n#>    <date>    \n#>  1 2021-12-15\n#>  2 2021-12-16\n#>  3 2021-12-17\n#>  4 2021-12-18\n#>  5 2021-12-19\n#>  6 2021-12-20\n#>  7 2021-12-21\n#>  8 2021-12-22\n#>  9 2021-12-23\n#> 10 2021-12-24"},{"path":"examples-of-preprocessing-and-models.html","id":"references","chapter":"3 Examples of Preprocessing and Models","heading":"3.6 References","text":"McDonald, Bien, Green, Hu, et al. “Can auxiliary indicators improve COVID-19\nforecasting hotspot prediction?.” Proceedings National Academy \nSciences 118.51 (2021): e2111453118. doi:10.1073/pnas.2111453118","code":""},{"path":"examples-of-preprocessing-and-models.html","id":"attribution","chapter":"3 Examples of Preprocessing and Models","heading":"3.7 Attribution","text":"object contains modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API.data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University\nbehalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020.","code":""}]
